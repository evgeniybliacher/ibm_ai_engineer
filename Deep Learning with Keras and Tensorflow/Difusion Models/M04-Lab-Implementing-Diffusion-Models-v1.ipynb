{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f8a6280-256d-41e1-8913-985ddbfcba77",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab84a4f-7efc-4c88-9a41-193e9f84c509",
   "metadata": {},
   "source": [
    "# **Lab: Implementing Diffusion Models**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606aa0b1-967b-41e5-a445-1bda3e2b5054",
   "metadata": {},
   "source": [
    "Estimated time needed: **45** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e051b57-b738-4d99-b60d-64eb5e70bbb5",
   "metadata": {},
   "source": [
    "In this lab, you will learn how to implement, train, and evaluate diffusion models using Keras. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8c4b33-da36-43cc-b6a0-c16a7eb93efd",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the end of this lab, you will: \n",
    "- Acquire practical understanding of diffusion model architectures, data processing, model training, and performance evaluation \n",
    "- Implement, train, and evaluate diffusion models using Keras \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a7efa9-6624-4851-9b12-4cdc0313687b",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f3609d-acaf-435d-bc33-68eddd2af1d3",
   "metadata": {},
   "source": [
    "### Prerequisites \n",
    "\n",
    "- Basic understanding of Python and Keras \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1308bd43-4e1f-4a32-98e0-1ca3b71bbb5c",
   "metadata": {},
   "source": [
    "### Steps \n",
    "\n",
    "#### Step 1: Preprocess data \n",
    "\n",
    "Prepare the MNIST data set for training by normalizing the pixel values and reshaping the images to have a single color channel. Normalization helps in faster convergence during training, and reshaping is required because the input layer of your diffusion model expects a three-dimensional tensor. \n",
    "\n",
    "**1. Load and preprocess the MNIST data set:**\n",
    "\n",
    "- Use Keras to load the MNIST data set. \n",
    "- Normalize the image pixel values to the range [0, 1]. \n",
    "\n",
    "**2. Reshape the Data:**\n",
    "- Expand the dimensions of the images to match the input shape required by the model (28x28x1). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258fc8f1-0bb5-4654-b607-a1209780feb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install tensorflow-cpu==2.16.2\n",
    "\n",
    "import os\n",
    "# Suppress oneDNN optimizations and lower TensorFlow logging level\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763bef99-835e-4542-8a24-386303dfaa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea66bd9-c1b6-4650-b196-a63a375f26da",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9964fab-1381-4841-b4eb-ec072e205400",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.compiler.mlir.quantization.stablehlo.quantization_config_pb2' has no attribute 'CalibrationOptions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mnist\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Input, Conv2D, Flatten, Dense, Reshape, Conv2DTranspose\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\__init__.py:51\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m bitwise\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compat\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m data\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\_api\\v2\\compat\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.compat namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m v1\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m v2\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m forward_compatibility_horizon \u001b[38;5;66;03m# line: 125\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\__init__.py:30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m bitwise\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compat\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m data\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\compat\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.compat namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m v1\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m v2\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m forward_compatibility_horizon \u001b[38;5;66;03m# line: 125\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\compat\\v1\\__init__.py:60\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m profiler\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m python_io\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m quantization\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m queue\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ragged\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\quantization\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.quantization namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgen_array_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fake_quant_with_min_max_args \u001b[38;5;66;03m# line: 3185\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgen_array_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fake_quant_with_min_max_args_gradient \u001b[38;5;66;03m# line: 3396\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\quantization\\experimental\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.quantization.experimental namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompiler\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmlir\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantize_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _QuantizationComponentSpec \u001b[38;5;28;01mas\u001b[39;00m QuantizationComponentSpec \u001b[38;5;66;03m# line: 45\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompiler\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmlir\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantize_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _QuantizationMethod \u001b[38;5;28;01mas\u001b[39;00m QuantizationMethod \u001b[38;5;66;03m# line: 41\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompiler\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmlir\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantize_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _QuantizationOptions \u001b[38;5;28;01mas\u001b[39;00m QuantizationOptions \u001b[38;5;66;03m# line: 37\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\compiler\\mlir\\quantization\\tensorflow\\python\\quantize_model.py:56\u001b[0m\n\u001b[0;32m     50\u001b[0m _UnitWiseQuantizationSpec \u001b[38;5;241m=\u001b[39m tf_export\u001b[38;5;241m.\u001b[39mtf_export(\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquantization.experimental.UnitWiseQuantizationSpec\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     52\u001b[0m )(quant_opts_pb2\u001b[38;5;241m.\u001b[39mUnitWiseQuantizationSpec)\n\u001b[0;32m     54\u001b[0m _PresetMethod \u001b[38;5;241m=\u001b[39m _QuantizationMethod\u001b[38;5;241m.\u001b[39mPresetMethod\n\u001b[0;32m     55\u001b[0m _CalibrationMethod \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m---> 56\u001b[0m     \u001b[43mstablehlo_quant_config_pb2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCalibrationOptions\u001b[49m\u001b[38;5;241m.\u001b[39mCalibrationMethod\n\u001b[0;32m     57\u001b[0m )\n\u001b[0;32m     59\u001b[0m _QuantizationComponent \u001b[38;5;241m=\u001b[39m _QuantizationComponentSpec\u001b[38;5;241m.\u001b[39mQuantizationComponent\n\u001b[0;32m     60\u001b[0m _TensorType \u001b[38;5;241m=\u001b[39m _QuantizationComponentSpec\u001b[38;5;241m.\u001b[39mTensorType\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.compiler.mlir.quantization.stablehlo.quantization_config_pb2' has no attribute 'CalibrationOptions'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Reshape, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load the data set  \n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "# Normalize the pixel values  \n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "# Expand dimensions to match the input shape (28, 28, 1)  \n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "# Add noise to the data\n",
    "noise_factor = 0.5\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
    "\n",
    "# Clip the values to be within the range [0, 1]\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfef8996-5e81-456b-8a7e-d882af59b553",
   "metadata": {},
   "source": [
    "#### Step 2: Build the diffusion model \n",
    "\n",
    "Build a simple diffusion model with an encoder that compresses the input image into a latent representation and a decoder that reconstructs the image from this representation. The model is compiled with the Adam optimizer and binary cross-entropy loss. \n",
    "\n",
    "**1. Define the encoder:**\n",
    "- Create an input layer with the shape (28, 28, 1). \n",
    "- Add two Conv2D layers with increasing filter sizes and ReLU activation. \n",
    "\n",
    "**2. Define the bottleneck:**\n",
    "- Add a flattened layer followed by a dense layer with ReLU activation. \n",
    "\n",
    "**3. Define the decoder:**\n",
    "- Add a Dense layer to expand the bottleneck representation.  \n",
    "- Reshape the output to match the original image dimensions.  \n",
    "- Add two Conv2DTranspose layers with decreasing filter sizes and ReLU activation.\n",
    "  \n",
    "**4. Compile the model:**\n",
    "- Use the Adam optimizer and binary cross-entropy loss. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5932ddce-92d0-42d6-9d0f-be6ff945bacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the diffusion model architecture with reduced complexity\n",
    "input_layer = Input(shape=(28, 28, 1))\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_layer)  # Reduced filters\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)  # Reduced filters\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)  # Reduced size\n",
    "x = Dense(28*28*32, activation='relu')(x)  # Reduced size\n",
    "x = Reshape((28, 28, 32))(x)\n",
    "x = Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)  # Reduced filters\n",
    "x = Conv2DTranspose(16, (3, 3), activation='relu', padding='same')(x)  # Reduced filters\n",
    "output_layer = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "diffusion_model = Model(input_layer, output_layer)\n",
    "\n",
    "# Compile the model with mixed precision and a different loss function\n",
    "diffusion_model.compile(optimizer='adam', loss='mean_squared_error')  # Using MSE for regression tasks\n",
    "\n",
    "# Summary of the optimized model\n",
    "diffusion_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eea41d-775f-40d4-8be1-e61daad034b8",
   "metadata": {},
   "source": [
    "#### Step 3: Add noise to the data \n",
    "\n",
    "Add random noise to the data set to simulate the diffusion process: \n",
    "- Add Gaussian noise to the training and test data sets.  \n",
    "- Clip the values to ensure they remain within the valid range [0, 1].  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66812d3f-073d-4f91-9121-ab18ff5c74d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache and prefetch the data using TensorFlow data pipelines for faster loading\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_noisy, x_train))\n",
    "train_dataset = train_dataset.cache().batch(64).prefetch(tf.data.AUTOTUNE)  # Reduced batch size\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_test_noisy, x_test))\n",
    "val_dataset = val_dataset.cache().batch(64).prefetch(tf.data.AUTOTUNE)  # Reduced batch size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860daa1b-a356-46ac-acfd-f7e25b1fecf4",
   "metadata": {},
   "source": [
    "#### Step 4: Train the diffusion model \n",
    "\n",
    "Train the diffusion model to denoise the MINIST images. Use the noisy images as input and the original images as the target, learning to reverse the noise addition process. \n",
    "- Use the ‘fit’ method to train the model on the noisy training data. \n",
    "- Set the number of epochs to 50 and the batch size to 128. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c89e776-f4ab-4cfa-b68c-615dfd88157f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement early stopping based on validation loss\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping and smaller batch size\n",
    "diffusion_model.fit(\n",
    "    train_dataset,\n",
    "    epochs=3,\n",
    "    shuffle=True,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2672625c-9d40-43e8-8104-be8a1436c44f",
   "metadata": {},
   "source": [
    "#### Step 5: Evaluate the diffusion model \n",
    "\n",
    "Evaluate the performance of the trained diffusion model by predicting the denoised images and visualizing the results. Comparing the original, noisy, and denoised images will help you understand how well the model has learned to remove noise from the images. \n",
    "\n",
    "**1. Reconstruct images:**\n",
    "- Use the diffusion model to predict the denoised test images.  \n",
    "- Compare the original, noisy, and denoised images. \n",
    "\n",
    "**2. Visualize the results:**\n",
    "- Plot a few examples of original, noisy, and denoised images side by side. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b93515-f310-4da1-95ca-e6dfee0c1983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predict the denoised images\n",
    "denoised_images = diffusion_model.predict(x_test_noisy)\n",
    "\n",
    "# Visualize the results\n",
    "n = 10  # Number of digits to display\n",
    "plt.figure(figsize=(20, 6))\n",
    "for i in range(n):\n",
    "    # Display original\n",
    "    ax = plt.subplot(3, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display noisy\n",
    "    ax = plt.subplot(3, n, i + 1 + n)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28), cmap='gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display denoised\n",
    "    ax = plt.subplot(3, n, i + 1 + 2*n)\n",
    "    plt.imshow(denoised_images[i].reshape(28, 28), cmap='gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cbe48b-fc76-4c82-bc5d-0d8bd3c16ce5",
   "metadata": {},
   "source": [
    "#### Step 6: Fine-tune the diffusion model \n",
    "\n",
    "Fine-tune the diffusion model by unfreezing some layers and retraining the model to improve its performance. \n",
    "\n",
    "**1. Unfreeze the model layers:** \n",
    "- Unfreeze the last few layers of the model to allow them to be retrained. \n",
    "\n",
    "**2. Compile and train the model:** \n",
    "- Recompile the model. \n",
    "- Train the model again for an additional 10 epochs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4243ee12-9f69-4046-9f38-f2648e5d6504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the top layers of the model\n",
    "for layer in diffusion_model.layers[-4:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Compile the model again\n",
    "diffusion_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Train the model again\n",
    "diffusion_model.fit(x_train_noisy, x_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=64,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(x_test_noisy, x_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d230bc-794f-4192-9888-132afb6e728b",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "### Exercise 1: Modify the noise factor  \n",
    "\n",
    "#### Objective: \n",
    "- Change the noise factor and see how it affects the model’s ability to denoise images.\n",
    "#### Instructions:  \n",
    "1. Change the noise factor to 0.3.  \n",
    "2. Add noise to the training and test data sets with the new noise factor.  \n",
    "3. Retrain the model with the new noisy data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6a669b-8f01-46d5-8346-af890fc295c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7d49c1-fa95-48f8-955d-7b2e4fe126d1",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "# Modify the noise factor to 0.3  \n",
    "noise_factor = 0.3  \n",
    "   \n",
    "# Add noise to the data with the new noise factor  \n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)  \n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)  \n",
    "  \n",
    "# Clip the values to be within the range [0, 1]  \n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)  \n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)  \n",
    "   \n",
    "# Retrain the model  \n",
    "diffusion_model.fit(x_train_noisy, x_train,    \n",
    "                    epochs=50,    \n",
    "                    batch_size=128,    \n",
    "                    shuffle=True,    \n",
    "                    validation_data=(x_test_noisy, x_test))  \n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdbd857-88c6-42df-8682-12380cbfd351",
   "metadata": {},
   "source": [
    "### Exercise 2 - Add more layers to the model  \n",
    "\n",
    "#### Objective: \n",
    "- Experiment with adding more layers to the model to see how it affects performance.\n",
    "\n",
    "#### Instructions:\n",
    "1. Add an additional Conv2D layer with 128 filters in the encoder.  \n",
    "2. Add an additional Conv2DTranspose layer with 128 filters in the decoder.  \n",
    "3. Rebuild, compile, and train the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162eae91-7861-4b96-a8a1-af7b553b6bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1515be8a-73b9-4d2c-90be-28e002c1d6bc",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "# Define the modified diffusion model architecture with additional layers\n",
    "input_layer = Input(shape=(28, 28, 1))\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x) # Additional layer\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(28*28*64, activation='relu')(x)\n",
    "x = Reshape((28, 28, 64))(x)\n",
    "x = Conv2DTranspose(128, (3, 3), activation='relu', padding='same')(x) # Additional layer\n",
    "x = Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n",
    "output_layer = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "diffusion_model = Model(input_layer, output_layer)\n",
    "\n",
    "# Compile the model  \n",
    "diffusion_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "   \n",
    "\n",
    "# Summary of the model  \n",
    "diffusion_model.summary()\n",
    "\n",
    "# Train the model  \n",
    "diffusion_model.fit(x_train_noisy, x_train,\n",
    "                    epochs=50,\n",
    "                    batch_size=128,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(x_test_noisy, x_test))\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ad53cb-1ce2-41b7-bab4-d4d9c1b1e8b0",
   "metadata": {},
   "source": [
    "### Exercise 3: Visualize the effect of noise  \n",
    "\n",
    "#### Objective: \n",
    "- Compare the impact of different noise levels on the denoising performance of the model.\n",
    "\n",
    "#### Instructions:  \n",
    "1. Add noise with different factors (e.g., 0.1, 0.5, 0.7) to the test data.  \n",
    "2. Use the model to predict the denoised images for each noise level.  \n",
    "3. Visualize the original, noisy, and denoised images side by side for each noise level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce10e275-706a-475b-a5fc-babc0affc9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ff5d58-2fb4-4140-8961-cbb0fd18d1c2",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "   \n",
    "\n",
    "# Function to add noise and predict denoised images\n",
    "def add_noise_and_predict(noise_factor):\n",
    "    x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
    "    x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "    denoised_images = diffusion_model.predict(x_test_noisy)\n",
    "    return x_test_noisy, denoised_images\n",
    "\n",
    "# Noise levels to test\n",
    "noise_levels = [0.1, 0.5, 0.7]\n",
    "   \n",
    "# Visualize the results\n",
    "n = 5  # Number of digits to display\n",
    "plt.figure(figsize=(20, 12))\n",
    "for idx, noise_factor in enumerate(noise_levels):\n",
    "    x_test_noisy, denoised_images = add_noise_and_predict(noise_factor)\n",
    "    \n",
    "    for i in range(n):\n",
    "        # Display original\n",
    "        ax = plt.subplot(3 * len(noise_levels), n, i + 1 + idx * 3 * n)\n",
    "        plt.imshow(x_test[i].reshape(28, 28), cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)  \n",
    "\n",
    "        if i == 0:\n",
    "            ax.set_title(f'Original (Noise: {noise_factor})')\n",
    "          \n",
    "        # Display noisy\n",
    "        ax = plt.subplot(3 * len(noise_levels), n, i + 1 + n + idx * 3 * n)\n",
    "        plt.imshow(x_test_noisy[i].reshape(28, 28), cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)  \n",
    "\n",
    "\n",
    "        # Display denoised\n",
    "        ax = plt.subplot(3 * len(noise_levels), n, i + 1 + 2 * n + idx * 3 * n)\n",
    "        plt.imshow(denoised_images[i].reshape(28, 28), cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)  \n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0973be-83a5-44cd-a05d-80dadfe22999",
   "metadata": {},
   "source": [
    "### Summary  \n",
    "\n",
    "By completing these exercises, students will:  \n",
    "1. Understand the impact of different noise factors on the model’s denoising capabilities.\n",
    "2. Learn how adding more layers to the model affects its performance.\n",
    "3. Visualize how different levels of noise affect the denoising results of the model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3733bf8-c459-46d6-8031-0521e6147109",
   "metadata": {},
   "source": [
    "### Conclusion \n",
    "\n",
    "Congratulations! You have gained practical experience in implementing diffusion models using Keras. You learned how to preprocess data, construct a basic diffusion model architecture, add noise to the data set, train the model, and evaluate its performance. Additionally, you explored fine-tuning techniques to enhance the model’s performance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097f545f-88e5-4dae-bba3-1df445117b89",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "prev_pub_hash": "7fa2b9c1faf3c0610fe958f16376a50e069db649db190e3bcc210b7f9e13f25e"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
