{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropogation\n",
    "This is a simple implementation of backpropagation for a neural network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./images/1674738205777.png \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_plotting = True\n",
    "is_verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_function(x):\n",
    "    return (2/ (1 + np.exp(-x))) - 1\n",
    "\n",
    "def derative_activation_function(x):\n",
    "    return 0.5 * (1 + x) * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_weights = np.array([[-0.2, 0.3, -0.4], [0.1, -0.3, -0.4]])\n",
    "output_layer_weights = np.array([0.2, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_forward(input_data):\n",
    "    # Calculate hidden layer output\n",
    "    hidden_layer_input = np.dot(hidden_layer_weights, input_data)\n",
    "    hidden_layer_output =[activation_function(hidden_layer_input) for i in hidden_layer_input]\n",
    "    if is_verbose:\n",
    "        print(f\"Hidden Layer Input: {hidden_layer_input}\")\n",
    "        print(f\"Hidden Layer Output: {hidden_layer_output}\")\n",
    "\n",
    "    # Calculate output layer output\n",
    "    output_layer_input = np.dot(output_layer_weights, hidden_layer_output)\n",
    "    output_layer_output = activation_function(output_layer_input)\n",
    "    if is_verbose:\n",
    "        print(f\"Output Layer Input: {output_layer_input}\")\n",
    "        print(f\"Output Layer Output: {output_layer_output}\")\n",
    "\n",
    "    return hidden_layer_output, output_layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = [\n",
    "  (-1, -1, -1, -1),\n",
    "  (-1, -1, 1, 1),\n",
    "  (-1, 1, -1, 1),\n",
    "  (-1, 1, 1, -1),\n",
    "  (1, -1, -1, 1),\n",
    "  (1, -1, 1, -1),\n",
    "  (1, 1, -1, -1),\n",
    "  (1, 1, 1, 1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propogation(epochs):\n",
    "    global hidden_layer_weights, output_layer_weights\n",
    "    for epoch in epochs:\n",
    "        input_data = np.array(epoch[:-1])\n",
    "        expected_output = epoch[-1]\n",
    "\n",
    "        # Forward pass\n",
    "        hidden_layer_output, output_layer_output = go_forward(input_data)\n",
    "\n",
    "        # Calculate error\n",
    "        error = expected_output - output_layer_output\n",
    "        if is_verbose:\n",
    "            print(f\"Error: {error}\")\n",
    "\n",
    "        # Backward pass\n",
    "        delta_output = error * derative_activation_function(output_layer_output)\n",
    "        if is_verbose:\n",
    "            print(f\"Delta Output: {delta_output}\")\n",
    "\n",
    "        delta_hidden = np.dot(delta_output, output_layer_weights) * derative_activation_function(hidden_layer_output)\n",
    "        if is_verbose:\n",
    "            print(f\"Delta Hidden: {delta_hidden}\")\n",
    "\n",
    "        # Update weights\n",
    "        output_layer_weights += 0.1 * delta_output * hidden_layer_output\n",
    "        hidden_layer_weights += 0.1 * np.outer(delta_hidden, input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Input: [0.3 0.6]\n",
      "Hidden Layer Output: [array([0.14888503, 0.29131261]), array([0.14888503, 0.29131261])]\n",
      "Output Layer Input: [0.07444252 0.14565631]\n",
      "Output Layer Output: [0.03720408 0.07269967]\n",
      "Epoch 0, Sample 0, Error: [-1.03720408 -1.07269967]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[22], line 16\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(input_data, learning_rate, epochs)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_verbose:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Sample \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \n\u001b[1;32m---> 16\u001b[0m d_hidden_layer \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(output_layer_weights, d_output) \u001b[38;5;241m*\u001b[39m \u001b[43mderative_activation_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_layer_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Update weights\u001b[39;00m\n\u001b[0;32m     19\u001b[0m output_layer_weights \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m d_output \u001b[38;5;241m*\u001b[39m hidden_layer_output\n",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m, in \u001b[0;36mderative_activation_function\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mderative_activation_function\u001b[39m(x):\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m x)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'list'"
     ]
    }
   ],
   "source": [
    "train(epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
